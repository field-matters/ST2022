{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399bcf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt update\n",
    "!apt -y install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1556690",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -c https://files.deeppavlov.ai/field-matters/releases/demo/asr_data.csv\n",
    "!wget -c https://files.deeppavlov.ai/field-matters/releases/demo/sound.zip\n",
    "!unzip sound.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ea3394",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('asr_data.csv') #your dataset here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c36b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fpath\"] = './audio_to_release/' + df[\"lang\"].astype(str) + \"/\" + df[\"source\"].astype(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6cfea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding paths to file to dataset\n",
    "df[\"fpath\"] = './audio_to_release/' + df[\"lang\"].astype(str) + \"/\" + df[\"source\"].astype(str)\n",
    "#removing spaces in dataset's paths\n",
    "def fix_path(path):\n",
    "    try:\n",
    "        os.rename(path, path.replace(' ', '_'))\n",
    "        return path\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "df['fpath'] = df['fpath'].apply(fix_path)\n",
    "\n",
    "df = df.reset_index() #adding indexes(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1490b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacer(path):\n",
    "    return path.replace(' ', '_')\n",
    "df['fpath'] = df['fpath'].apply(replacer)\n",
    "df = df.reset_index() #adding indexes(id)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba69eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir = './new_audio' #new directory for cut files\n",
    "if os.path.exists(new_dir) is False:\n",
    "    os.mkdir(new_dir)\n",
    "else:\n",
    "    print('folder already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4de1591",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ffmpeg_log\n",
    "\n",
    "def cutter(row): #cutting files accroding to timecodes\n",
    "    fpath, start, end, index = row[\"fpath\"], row[\"start\"], row[\"end\"], row[\"index\"]\n",
    "    !ffmpeg -n -i {fpath} -ss {str(start)} -to {str(end)} -ar 16000 \\\n",
    "     {'./new_audio/' + str(index)}.wav \\\n",
    "     2> ffmpeg_log/{index}.log\n",
    "\n",
    "    \n",
    "df.progress_apply(cutter, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93919e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making column for paths of cut files\n",
    "df['new_path'] = df['index'].apply(lambda x: './new_audio/' + str(x) + '.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17260ba",
   "metadata": {},
   "source": [
    "# ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ccfeec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!apt update\n",
    "!pip install transformers datasets phonemizer\n",
    "!apt install espeak\n",
    "!pip install pydub\n",
    "!pip install transformers --upgrade\n",
    "!pip install torchaudio\n",
    "!pip install tqdm --upgrade\n",
    "!pip install torchaudio --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3147d191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba047513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import __version__ as transformers_ver\n",
    "from tqdm import __version__ as tqdm_ver\n",
    "from torch import __version__ as torch_ver\n",
    "from torchaudio import __version__ as torchaudio_ver\n",
    "from pandas import __version__ as pd_ver\n",
    "print(f\"transformers_ver:\\t{transformers_ver}\")\n",
    "print(f\"tqdm_ver:\\t{tqdm_ver}\")\n",
    "print(f\"torch_ver:\\t{torch_ver}\")\n",
    "print(f\"torchaudio_ver:\\t{torchaudio_ver}\")\n",
    "print(f\"pandas_ver:\\t{pd_ver}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310c2b74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCTC, Wav2Vec2Processor\n",
    "\n",
    "model = AutoModelForCTC.from_pretrained(\"facebook/wav2vec2-xlsr-53-espeak-cv-ft\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-xlsr-53-espeak-cv-ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8af507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; cuda_num = os.getenv(\"CUDA_VISIBLE_DEVICES\")\n",
    "\n",
    "!nvidia-smi -i {cuda_num}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647e7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "device = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "def recognizer(fpath):\n",
    "    try:\n",
    "        waveform, sample_rate = torchaudio.load(fpath)\n",
    "        waveform = waveform.to(device)\n",
    "        logits = model(waveform).logits\n",
    "        pred_ids = torch.argmax(logits, dim=-1)\n",
    "        pred_str = processor.batch_decode(pred_ids)[0]\n",
    "        return pred_str\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07949fda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['recognized'] = df['new_path'].progress_apply(recognizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62254f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transcription'] = df['transcription'].apply(lambda x: x.strip('.«,').replace('=', '').replace(' ', '').replace('Ø', ' '))#clearing punctuation marks and spaces\n",
    "df['transcription'] = df['transcription'].apply(lambda x: re.sub('\\(.+?\\)', '', x))\n",
    "df['recognized'] = df['recognized'].str.replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550e1f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling empty strings\n",
    "df['transcription'] = df['transcription'].apply(lambda s: s if s else '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16369dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('asr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e9dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"transcription\", \"recognized\"]].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1582028",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a7e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install abydos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98120e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abydos import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d373eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonetic = distance.PhoneticEditDistance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e65ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phonetic_metric(row):\n",
    "    try:\n",
    "        phonetic = distance.PhoneticEditDistance()\n",
    "        result = phonetic.dist(row['transcription'], row['recognized'])\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95f9cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['phonetic_ev'] = df.apply(phonetic_metric, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f622061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['transcription', 'recognized', 'phonetic_ev']].sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
